{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8ZmVKhQFuhwEaZWhcdZtA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cdrc1103/NER/blob/main/Bert_for_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "G95RVb9KOZFx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6N82tmQOTMz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
        "example = \"\"\"\n",
        "My name is Wolfgang and I live in Berlin. Recently, I started working \n",
        "at Capgemini were I work as a data scientist.\n",
        "\"\"\"\n",
        "\n",
        "ner_results = nlp(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObYUSWLQoza2",
        "outputId": "66eff151-a99a-4bb8-e811-c32e67294ca6"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-PER', 'score': 0.99913836, 'index': 4, 'word': 'Wolfgang', 'start': 12, 'end': 20}, {'entity': 'B-LOC', 'score': 0.9996517, 'index': 9, 'word': 'Berlin', 'start': 35, 'end': 41}, {'entity': 'B-ORG', 'score': 0.99671835, 'index': 17, 'word': 'Cap', 'start': 75, 'end': 78}, {'entity': 'I-ORG', 'score': 0.9911644, 'index': 18, 'word': '##ge', 'start': 78, 'end': 80}, {'entity': 'I-ORG', 'score': 0.9921948, 'index': 19, 'word': '##mini', 'start': 80, 'end': 84}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "\n",
        "def join_results(results):\n",
        "  joined_results = []\n",
        "  for result in results:\n",
        "    if result[\"entity\"][0] == \"I\" and joined_results:\n",
        "      joined_results[-1][\"end\"] = result[\"end\"]\n",
        "      joined_results[-1][\"word\"] += remove_prefix(result[\"word\"], \"##\")\n",
        "      joined_results[-1][\"score\"] = min(joined_results[-1][\"score\"], result[\"score\"])\n",
        "    else:\n",
        "      joined_results.append(result)\n",
        "  return joined_results\n",
        "\n",
        "\n",
        "def clean_result(result):\n",
        "  result = remove_prefix(result, \"-\")\n",
        "  result[\"label\"] = result[\"entity\"]\n",
        "  return result\n",
        "\n",
        "\n",
        "def remove_prefix(result, prefix):\n",
        "  result[\"entity\"] =  result[\"entity\"].split(prefix, 1)[1]\n",
        "  return result\n",
        "\n",
        "\n",
        "def convert_to_displacy_format(example, ner_results, threshold=0.9):\n",
        "  results = copy.deepcopy(ner_results)\n",
        "  joined_results = join_results(results)\n",
        "  filtered_results = [r for r in joined_results if r[\"score\"] > threshold]\n",
        "  cleaned_results = [clean_result(r) for r in filtered_results]\n",
        "\n",
        "  return [{\n",
        "      \"text\": example,\n",
        "      \"ents\": cleaned_results,\n",
        "      \"title\": None\n",
        "  }]"
      ],
      "metadata": {
        "id": "0kO8BchosEqN"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"##test\".split(\"##\", 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYZ9-E-P9ndu",
        "outputId": "8a94c53f-3f7c-41d6-8a5d-794a212f9ac3"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy_results = convert_to_displacy_format(example, ner_results)\n",
        "displacy.render(displacy_results, style=\"ent\", jupyter=True, manual=True)"
      ],
      "metadata": {
        "id": "NbzgO7muQLJS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}